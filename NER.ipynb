{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import jieba.posseg\n",
    "import numpy as np\n",
    "filepath = r\"D:\\DEV\\businessInfomationProject\\NER\\BosonNLP_NER_6C.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计加入用户词典\n",
    "#company_name person_name location org_name\n",
    "#正常分句子，清洗，匹配tag\n",
    "#训练\n",
    "#predict\n",
    "\n",
    "def to_ix_processing(pairs):\n",
    "    word_to_ix = {}\n",
    "    tag_to_ix= {\"<START>\":1,\"<STOP>\":2,\"<UNK>\":3}\n",
    "    for sentence, tags in pairs:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "        for tag in tags:\n",
    "            if tag not in tag_to_ix:\n",
    "                tag_to_ix[tag] = len(tag_to_ix)+1\n",
    "    return word_to_ix,tag_to_ix\n",
    "    \n",
    "\n",
    "def load_samplefile(filepath):\n",
    "    with open(filepath,encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "        data = re.sub(r\"\\n\\n\",\"\",data)\n",
    "        data = re.sub(r\"\\d+\",\"MM\",data)\n",
    "        for i in ([\"一\",\"二\",\"三\",\"四\",\"五\",\"六\",\"七\",\"八\",\"九\",\"十\"]):\n",
    "            data = re.sub(i,\"MM\",data)   \n",
    "    return data\n",
    "\n",
    "def cut_sentence(data):\n",
    "    sentLst = data.split(\"。\")    \n",
    "    return sentLst\n",
    "\n",
    "#解析数据，输出用户字典和实体标注名称列表\n",
    "def user_dict_count(data):\n",
    "    regxLst = re.findall(r'\\b{{[a-z].*?}}',data)\n",
    "    dictWord_dict = {}\n",
    "    for item in regxLst:   \n",
    "        word = item[2:-2].split(\":\")[1]\n",
    "        entity = item[2:-2].split(\":\")[0]\n",
    "        if word not in dictWord_dict.keys():\n",
    "            dictWord_dict[word] = entity\n",
    "        \n",
    "    del dictWord_dict['MM']\n",
    "    return dictWord_dict\n",
    "\n",
    "#添加用户字典\n",
    "def add_userdict(user_dict):\n",
    "    jieba.load_userdict(user_dict)\n",
    "    return\n",
    "\n",
    "def filterdata(text,entitys):\n",
    "    text = text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "    # 去除标点符号\n",
    "    punctuation = \"\"\"{}➊➋➌➍➎➏➐➑➒➓+，◆。！？｡＂＃＄％＆＇\\/()（）:＊＋*\"－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏\"\"\"+\"\".join(entitys)\n",
    "    re_punctuation = \"[{}]+\".format(punctuation)\n",
    "    text = re.sub(re_punctuation, \"\", text)  \n",
    "    return text\n",
    "\n",
    "#返回分词结果和词性  \n",
    "#分词\n",
    "#词和词对应的词性返回\n",
    "def dosegment_all(sentence,dictWord_dict):\n",
    "    '''\n",
    "    带词性标注，对句子进行分词，不排除停词等\n",
    "    :param sentence:输入字符\n",
    "    :return:\n",
    "    '''\n",
    "    sentence_seged = jieba.posseg.cut(sentence.strip())\n",
    "    wordLst = []\n",
    "    flagLst = []\n",
    "    for x in sentence_seged:      \n",
    "        wordLst.append(x.word)\n",
    "        if x.word in dictWord_dict.keys():\n",
    "            flagLst.append(dictWord_dict[x.word])\n",
    "        else:\n",
    "            flagLst.append(x.flag)    \n",
    "    return [wordLst,flagLst]\n",
    "    \n",
    " \n",
    "def pairsPrepare(filepath):\n",
    "    #读取数据\n",
    "    data = load_samplefile(filepath) \n",
    "    sentLst = cut_sentence(data)\n",
    "    user_dict = user_dict_count(data)\n",
    "    add_userdict(list(user_dict.keys()))\n",
    "    pairs = []\n",
    "    entitys = list(set(user_dict.values()))\n",
    "    for sent in sentLst:\n",
    "        text = filterdata(sent,entitys)\n",
    "        pairs.append(dosegment_all(text,user_dict))\n",
    "    return pairs,entitys,user_dict\n",
    "\n",
    "def pairs_trim(pairs,min_len = 3):\n",
    "    pairs_trimed = []\n",
    "    for i ,(w,t) in enumerate(pairs):\n",
    "        if len(w) > min_len:\n",
    "            pairs_trimed.append(pairs[i])\n",
    "\n",
    "    return pairs_trimed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs,entitys,user_dict = pairsPrepare(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs = pairs_trim(pairs,min_len = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "torch.manual_seed(1935)\n",
    "\n",
    "\n",
    "#取向量最大值\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "#将词映射成id\n",
    "def prepare_sequence(seq, to_ix):   \n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix.keys():\n",
    "            w = UNK_TAG \n",
    "        idxs.append(to_ix[w])\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        \n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "        if feats.size(0) == 0:return 0\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):    \n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        #print(forward_score)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "\n",
    "        return  forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_ix_w,to_ix_l = to_ix_processing(pairs)  \n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "UNK_TAG  = \"<UNK>\"\n",
    "\n",
    "EPOCHES =200\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 500\n",
    "BATCH_SIZE = 64\n",
    "# Make up some training data\n",
    "pairs,entitys,user_dict = pairsPrepare(filepath)\n",
    "pairs = pairs_trim(pairs,min_len = 3)\n",
    "to_ix_w,to_ix_l = to_ix_processing(pairs)\n",
    "training_batch_data = [[random.choice(pairs[:-300]) for _ in range(BATCH_SIZE)] for _ in range(EPOCHES)]\n",
    "test_batch_data = pairs[-300:]   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0005\n",
    "model = BiLSTM_CRF(len(to_ix_w), to_ix_l, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "\n",
    "def train(model,training_batch,to_ix_w,to_ix_l):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    \n",
    "    for i,pair in enumerate(training_batch): \n",
    "        \n",
    "        \n",
    "        \n",
    "        sentence, tags = pair[0],pair[1]\n",
    "        #print(sentence)\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, to_ix_w)\n",
    "\n",
    "        targets = torch.tensor([to_ix_l[t] for t in tags], dtype=torch.long)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "        \n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()/len(sentence_in)\n",
    "        \n",
    "        \n",
    "        log_interval = 20\n",
    "        if i % log_interval == 0 and i != 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | '\n",
    "                  'lr {:02.6f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.5f} |'.format(\n",
    "                    epoch, lr,\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "            \n",
    "def evaluate(eval_model, data_source,to_ix_w, to_ix_l):\n",
    "    eval_model.eval()  # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for x_k, y_k in data_source:\n",
    "            sentence_k = prepare_sequence(x_k, to_ix_w)\n",
    "            targets_k = torch.tensor([to_ix_l[t] for t in y_k], dtype=torch.long)\n",
    "            loss_test = eval_model.neg_log_likelihood(sentence_k, targets_k)\n",
    "            total_loss += float(loss_test)/len(sentence_k)\n",
    "    return total_loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 0.000500 | ms/batch 327.45 | loss 4.41432 |\n",
      "| epoch   0 | lr 0.000500 | ms/batch 331.72 | loss 3.98526 |\n",
      "| epoch   0 | lr 0.000500 | ms/batch 453.04 | loss 3.33100 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   0 | time: 42.55s | valid loss 882.30 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   1 | lr 0.000500 | ms/batch 367.47 | loss 3.12512 |\n",
      "| epoch   1 | lr 0.000500 | ms/batch 336.85 | loss 2.82217 |\n",
      "| epoch   1 | lr 0.000500 | ms/batch 350.61 | loss 2.73320 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 41.59s | valid loss 769.27 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 | lr 0.000500 | ms/batch 477.02 | loss 2.75770 |\n",
      "| epoch   2 | lr 0.000500 | ms/batch 364.18 | loss 2.53614 |\n",
      "| epoch   2 | lr 0.000500 | ms/batch 364.33 | loss 2.33320 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 43.98s | valid loss 697.94 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 | lr 0.000500 | ms/batch 291.47 | loss 2.54446 |\n",
      "| epoch   3 | lr 0.000500 | ms/batch 410.20 | loss 2.29515 |\n",
      "| epoch   3 | lr 0.000500 | ms/batch 440.77 | loss 2.27032 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 42.66s | valid loss 659.69 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 | lr 0.000500 | ms/batch 350.26 | loss 2.44238 |\n",
      "| epoch   4 | lr 0.000500 | ms/batch 379.93 | loss 2.16728 |\n",
      "| epoch   4 | lr 0.000500 | ms/batch 352.56 | loss 2.11861 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 41.40s | valid loss 627.11 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 | lr 0.000500 | ms/batch 391.35 | loss 2.16144 |\n",
      "| epoch   5 | lr 0.000500 | ms/batch 344.98 | loss 1.95114 |\n",
      "| epoch   5 | lr 0.000500 | ms/batch 350.16 | loss 1.92386 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 41.69s | valid loss 593.99 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 | lr 0.000500 | ms/batch 381.88 | loss 2.00173 |\n",
      "| epoch   6 | lr 0.000500 | ms/batch 351.96 | loss 1.79906 |\n",
      "| epoch   6 | lr 0.000500 | ms/batch 346.27 | loss 1.77130 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 41.69s | valid loss 566.93 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 | lr 0.000500 | ms/batch 363.88 | loss 1.98062 |\n",
      "| epoch   7 | lr 0.000500 | ms/batch 330.96 | loss 1.83265 |\n",
      "| epoch   7 | lr 0.000500 | ms/batch 369.61 | loss 1.74222 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 41.15s | valid loss 546.38 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 | lr 0.000500 | ms/batch 420.47 | loss 1.89849 |\n",
      "| epoch   8 | lr 0.000500 | ms/batch 307.28 | loss 1.85111 |\n",
      "| epoch   8 | lr 0.000500 | ms/batch 325.33 | loss 1.87106 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 40.97s | valid loss 533.33 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 | lr 0.000500 | ms/batch 320.79 | loss 1.87141 |\n",
      "| epoch   9 | lr 0.000500 | ms/batch 363.93 | loss 1.62149 |\n",
      "| epoch   9 | lr 0.000500 | ms/batch 391.10 | loss 1.68027 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 42.04s | valid loss 522.88 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 | lr 0.000500 | ms/batch 370.26 | loss 1.96662 |\n",
      "| epoch  10 | lr 0.000500 | ms/batch 320.19 | loss 1.84870 |\n",
      "| epoch  10 | lr 0.000500 | ms/batch 387.16 | loss 1.62345 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 41.22s | valid loss 514.19 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 | lr 0.000500 | ms/batch 324.33 | loss 1.84585 |\n",
      "| epoch  11 | lr 0.000500 | ms/batch 370.26 | loss 1.46280 |\n",
      "| epoch  11 | lr 0.000500 | ms/batch 336.95 | loss 1.59447 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 40.20s | valid loss 502.00 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 | lr 0.000500 | ms/batch 345.28 | loss 1.74445 |\n",
      "| epoch  12 | lr 0.000500 | ms/batch 341.04 | loss 1.73986 |\n",
      "| epoch  12 | lr 0.000500 | ms/batch 273.92 | loss 1.66971 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 40.07s | valid loss 486.41 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 | lr 0.000500 | ms/batch 332.11 | loss 1.59011 |\n",
      "| epoch  13 | lr 0.000500 | ms/batch 349.17 | loss 1.72249 |\n",
      "| epoch  13 | lr 0.000500 | ms/batch 320.19 | loss 1.49283 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 39.50s | valid loss 475.97 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 | lr 0.000500 | ms/batch 418.18 | loss 1.70935 |\n",
      "| epoch  14 | lr 0.000500 | ms/batch 382.48 | loss 1.70405 |\n",
      "| epoch  14 | lr 0.000500 | ms/batch 313.11 | loss 1.44205 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 41.81s | valid loss 462.05 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 | lr 0.000500 | ms/batch 392.00 | loss 1.54923 |\n",
      "| epoch  15 | lr 0.000500 | ms/batch 356.35 | loss 1.59343 |\n",
      "| epoch  15 | lr 0.000500 | ms/batch 316.10 | loss 1.63616 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 41.53s | valid loss 456.81 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 | lr 0.000500 | ms/batch 562.42 | loss 1.53143 |\n",
      "| epoch  16 | lr 0.000500 | ms/batch 322.09 | loss 1.66048 |\n",
      "| epoch  16 | lr 0.000500 | ms/batch 577.17 | loss 1.58677 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 49.35s | valid loss 447.23 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 | lr 0.000500 | ms/batch 397.34 | loss 1.53391 |\n",
      "| epoch  17 | lr 0.000500 | ms/batch 358.59 | loss 1.35336 |\n",
      "| epoch  17 | lr 0.000500 | ms/batch 314.11 | loss 1.54895 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 41.90s | valid loss 437.95 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 | lr 0.000500 | ms/batch 391.51 | loss 1.39362 |\n",
      "| epoch  18 | lr 0.000500 | ms/batch 370.46 | loss 1.54656 |\n",
      "| epoch  18 | lr 0.000500 | ms/batch 318.40 | loss 1.43761 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 44.15s | valid loss 432.04 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 | lr 0.000500 | ms/batch 449.95 | loss 1.28734 |\n",
      "| epoch  19 | lr 0.000500 | ms/batch 394.44 | loss 1.39563 |\n",
      "| epoch  19 | lr 0.000500 | ms/batch 398.03 | loss 1.45943 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 45.87s | valid loss 430.20 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  20 | lr 0.000500 | ms/batch 372.60 | loss 1.41039 |\n",
      "| epoch  20 | lr 0.000500 | ms/batch 290.72 | loss 1.36266 |\n",
      "| epoch  20 | lr 0.000500 | ms/batch 319.10 | loss 1.42403 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 40.97s | valid loss 421.33 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 | lr 0.000500 | ms/batch 510.36 | loss 1.31350 |\n",
      "| epoch  21 | lr 0.000500 | ms/batch 340.54 | loss 1.46281 |\n",
      "| epoch  21 | lr 0.000500 | ms/batch 434.46 | loss 1.35527 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 46.11s | valid loss 416.02 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 | lr 0.000500 | ms/batch 384.72 | loss 1.49031 |\n",
      "| epoch  22 | lr 0.000500 | ms/batch 389.01 | loss 1.12445 |\n",
      "| epoch  22 | lr 0.000500 | ms/batch 386.02 | loss 1.54324 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 42.81s | valid loss 406.12 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 | lr 0.000500 | ms/batch 378.59 | loss 1.17326 |\n",
      "| epoch  23 | lr 0.000500 | ms/batch 363.25 | loss 1.33601 |\n",
      "| epoch  23 | lr 0.000500 | ms/batch 392.95 | loss 1.19134 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 43.24s | valid loss 398.79 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 | lr 0.000500 | ms/batch 401.05 | loss 1.20755 |\n",
      "| epoch  24 | lr 0.000500 | ms/batch 396.54 | loss 1.40118 |\n",
      "| epoch  24 | lr 0.000500 | ms/batch 381.38 | loss 1.15647 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 43.76s | valid loss 398.72 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 | lr 0.000500 | ms/batch 327.37 | loss 1.33608 |\n",
      "| epoch  25 | lr 0.000500 | ms/batch 418.41 | loss 1.37134 |\n",
      "| epoch  25 | lr 0.000500 | ms/batch 320.74 | loss 1.39757 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 41.84s | valid loss 389.70 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 | lr 0.000500 | ms/batch 346.07 | loss 1.36233 |\n",
      "| epoch  26 | lr 0.000500 | ms/batch 331.72 | loss 1.34159 |\n",
      "| epoch  26 | lr 0.000500 | ms/batch 447.80 | loss 1.20526 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 42.89s | valid loss 386.90 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 | lr 0.000500 | ms/batch 358.34 | loss 1.28184 |\n",
      "| epoch  27 | lr 0.000500 | ms/batch 356.40 | loss 1.16153 |\n",
      "| epoch  27 | lr 0.000500 | ms/batch 305.23 | loss 1.18035 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 41.10s | valid loss 381.75 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 | lr 0.000500 | ms/batch 365.07 | loss 1.31170 |\n",
      "| epoch  28 | lr 0.000500 | ms/batch 352.31 | loss 1.07636 |\n",
      "| epoch  28 | lr 0.000500 | ms/batch 449.31 | loss 1.19390 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 43.52s | valid loss 377.66 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 | lr 0.000500 | ms/batch 384.08 | loss 1.16065 |\n",
      "| epoch  29 | lr 0.000500 | ms/batch 340.74 | loss 1.28141 |\n",
      "| epoch  29 | lr 0.000500 | ms/batch 335.85 | loss 1.28784 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 41.59s | valid loss 374.42 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 | lr 0.000500 | ms/batch 420.88 | loss 1.20824 |\n",
      "| epoch  30 | lr 0.000500 | ms/batch 377.69 | loss 1.10433 |\n",
      "| epoch  30 | lr 0.000500 | ms/batch 348.12 | loss 1.21631 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 42.24s | valid loss 371.94 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 | lr 0.000500 | ms/batch 344.28 | loss 1.31357 |\n",
      "| epoch  31 | lr 0.000500 | ms/batch 384.97 | loss 0.94762 |\n",
      "| epoch  31 | lr 0.000500 | ms/batch 398.03 | loss 0.98020 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 42.26s | valid loss 366.38 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 | lr 0.000500 | ms/batch 362.63 | loss 1.18781 |\n",
      "| epoch  32 | lr 0.000500 | ms/batch 378.99 | loss 0.96805 |\n",
      "| epoch  32 | lr 0.000500 | ms/batch 338.94 | loss 1.03310 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 41.82s | valid loss 360.91 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 | lr 0.000500 | ms/batch 359.49 | loss 1.15853 |\n",
      "| epoch  33 | lr 0.000500 | ms/batch 377.04 | loss 0.95382 |\n",
      "| epoch  33 | lr 0.000500 | ms/batch 376.59 | loss 1.16434 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 42.61s | valid loss 357.62 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 | lr 0.000500 | ms/batch 367.52 | loss 1.01465 |\n",
      "| epoch  34 | lr 0.000500 | ms/batch 381.68 | loss 0.99220 |\n",
      "| epoch  34 | lr 0.000500 | ms/batch 370.81 | loss 1.17545 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 41.87s | valid loss 355.04 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 | lr 0.000500 | ms/batch 324.48 | loss 1.25556 |\n",
      "| epoch  35 | lr 0.000500 | ms/batch 368.86 | loss 1.04580 |\n",
      "| epoch  35 | lr 0.000500 | ms/batch 393.30 | loss 1.12733 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 41.23s | valid loss 346.91 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 | lr 0.000500 | ms/batch 469.39 | loss 1.14591 |\n",
      "| epoch  36 | lr 0.000500 | ms/batch 371.36 | loss 0.90505 |\n",
      "| epoch  36 | lr 0.000500 | ms/batch 392.20 | loss 0.94668 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 44.52s | valid loss 343.95 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 | lr 0.000500 | ms/batch 378.99 | loss 1.10617 |\n",
      "| epoch  37 | lr 0.000500 | ms/batch 402.22 | loss 1.03679 |\n",
      "| epoch  37 | lr 0.000500 | ms/batch 373.45 | loss 1.14067 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 43.21s | valid loss 342.21 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 | lr 0.000500 | ms/batch 349.27 | loss 1.15580 |\n",
      "| epoch  38 | lr 0.000500 | ms/batch 308.47 | loss 1.06691 |\n",
      "| epoch  38 | lr 0.000500 | ms/batch 308.23 | loss 1.09659 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 38.96s | valid loss 338.88 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 | lr 0.000500 | ms/batch 417.98 | loss 1.03117 |\n",
      "| epoch  39 | lr 0.000500 | ms/batch 397.14 | loss 1.10476 |\n",
      "| epoch  39 | lr 0.000500 | ms/batch 438.63 | loss 1.13370 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 45.69s | valid loss 335.29 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  40 | lr 0.000500 | ms/batch 400.18 | loss 0.95975 |\n",
      "| epoch  40 | lr 0.000500 | ms/batch 317.40 | loss 0.95380 |\n",
      "| epoch  40 | lr 0.000500 | ms/batch 365.32 | loss 0.84854 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 41.88s | valid loss 331.15 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 | lr 0.000500 | ms/batch 346.72 | loss 1.09421 |\n",
      "| epoch  41 | lr 0.000500 | ms/batch 313.16 | loss 1.16849 |\n",
      "| epoch  41 | lr 0.000500 | ms/batch 389.63 | loss 0.79530 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 40.63s | valid loss 330.49 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 | lr 0.000500 | ms/batch 369.16 | loss 1.04238 |\n",
      "| epoch  42 | lr 0.000500 | ms/batch 397.24 | loss 0.96892 |\n",
      "| epoch  42 | lr 0.000500 | ms/batch 328.77 | loss 1.19003 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 41.48s | valid loss 325.45 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 | lr 0.000500 | ms/batch 403.52 | loss 0.85870 |\n",
      "| epoch  43 | lr 0.000500 | ms/batch 409.20 | loss 1.05304 |\n",
      "| epoch  43 | lr 0.000500 | ms/batch 313.51 | loss 1.02310 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 41.84s | valid loss 323.87 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 | lr 0.000500 | ms/batch 349.37 | loss 0.99994 |\n",
      "| epoch  44 | lr 0.000500 | ms/batch 335.10 | loss 0.97619 |\n",
      "| epoch  44 | lr 0.000500 | ms/batch 341.89 | loss 0.95322 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 40.68s | valid loss 323.15 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 | lr 0.000500 | ms/batch 354.05 | loss 1.04746 |\n",
      "| epoch  45 | lr 0.000500 | ms/batch 402.32 | loss 0.99292 |\n",
      "| epoch  45 | lr 0.000500 | ms/batch 387.86 | loss 0.92774 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 43.06s | valid loss 317.47 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 | lr 0.000500 | ms/batch 447.16 | loss 0.95883 |\n",
      "| epoch  46 | lr 0.000500 | ms/batch 369.76 | loss 0.86753 |\n",
      "| epoch  46 | lr 0.000500 | ms/batch 405.71 | loss 0.79713 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 44.65s | valid loss 314.11 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 | lr 0.000500 | ms/batch 466.60 | loss 0.92946 |\n",
      "| epoch  47 | lr 0.000500 | ms/batch 355.15 | loss 0.95479 |\n",
      "| epoch  47 | lr 0.000500 | ms/batch 371.78 | loss 0.81478 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 45.20s | valid loss 308.77 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 | lr 0.000500 | ms/batch 505.70 | loss 0.94384 |\n",
      "| epoch  48 | lr 0.000500 | ms/batch 393.10 | loss 0.82350 |\n",
      "| epoch  48 | lr 0.000500 | ms/batch 411.10 | loss 1.04509 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 46.87s | valid loss 308.53 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 | lr 0.000500 | ms/batch 392.05 | loss 0.96473 |\n",
      "| epoch  49 | lr 0.000500 | ms/batch 408.56 | loss 0.74687 |\n",
      "| epoch  49 | lr 0.000500 | ms/batch 400.88 | loss 0.72835 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 44.89s | valid loss 301.57 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 | lr 0.000500 | ms/batch 481.01 | loss 1.10336 |\n",
      "| epoch  50 | lr 0.000500 | ms/batch 378.64 | loss 0.93923 |\n",
      "| epoch  50 | lr 0.000500 | ms/batch 370.86 | loss 0.93909 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 45.23s | valid loss 301.15 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 | lr 0.000500 | ms/batch 439.18 | loss 0.78210 |\n",
      "| epoch  51 | lr 0.000500 | ms/batch 359.59 | loss 0.79522 |\n",
      "| epoch  51 | lr 0.000500 | ms/batch 495.55 | loss 1.07963 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 46.25s | valid loss 302.69 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 | lr 0.000500 | ms/batch 445.61 | loss 0.86919 |\n",
      "| epoch  52 | lr 0.000500 | ms/batch 360.14 | loss 0.74637 |\n",
      "| epoch  52 | lr 0.000500 | ms/batch 432.84 | loss 0.83528 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 45.00s | valid loss 298.43 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 | lr 0.000500 | ms/batch 398.73 | loss 1.03168 |\n",
      "| epoch  53 | lr 0.000500 | ms/batch 347.82 | loss 0.91850 |\n",
      "| epoch  53 | lr 0.000500 | ms/batch 404.62 | loss 0.91664 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 42.59s | valid loss 295.06 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 | lr 0.000500 | ms/batch 398.88 | loss 0.66025 |\n",
      "| epoch  54 | lr 0.000500 | ms/batch 369.16 | loss 0.73537 |\n",
      "| epoch  54 | lr 0.000500 | ms/batch 317.20 | loss 0.89430 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 41.96s | valid loss 294.51 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 | lr 0.000500 | ms/batch 358.49 | loss 0.75847 |\n",
      "| epoch  55 | lr 0.000500 | ms/batch 387.46 | loss 0.72653 |\n",
      "| epoch  55 | lr 0.000500 | ms/batch 361.38 | loss 0.69089 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 41.81s | valid loss 292.30 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 | lr 0.000500 | ms/batch 380.08 | loss 0.78653 |\n",
      "| epoch  56 | lr 0.000500 | ms/batch 373.85 | loss 0.74239 |\n",
      "| epoch  56 | lr 0.000500 | ms/batch 365.57 | loss 0.93225 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 42.76s | valid loss 288.69 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  57 | lr 0.000500 | ms/batch 400.73 | loss 0.66258 |\n",
      "| epoch  57 | lr 0.000500 | ms/batch 402.42 | loss 0.83920 |\n",
      "| epoch  57 | lr 0.000500 | ms/batch 391.20 | loss 0.76246 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 43.55s | valid loss 284.67 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 | lr 0.000500 | ms/batch 376.39 | loss 0.71420 |\n",
      "| epoch  58 | lr 0.000500 | ms/batch 349.32 | loss 0.73209 |\n",
      "| epoch  58 | lr 0.000500 | ms/batch 367.47 | loss 0.76660 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 41.87s | valid loss 283.00 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 | lr 0.000500 | ms/batch 360.09 | loss 0.80163 |\n",
      "| epoch  59 | lr 0.000500 | ms/batch 385.22 | loss 1.00067 |\n",
      "| epoch  59 | lr 0.000500 | ms/batch 434.34 | loss 0.97460 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 43.95s | valid loss 278.54 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  60 | lr 0.000500 | ms/batch 410.65 | loss 0.69811 |\n",
      "| epoch  60 | lr 0.000500 | ms/batch 466.55 | loss 0.80276 |\n",
      "| epoch  60 | lr 0.000500 | ms/batch 368.76 | loss 0.82386 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 45.00s | valid loss 279.04 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  61 | lr 0.000500 | ms/batch 429.10 | loss 0.77614 |\n",
      "| epoch  61 | lr 0.000500 | ms/batch 414.49 | loss 0.73145 |\n",
      "| epoch  61 | lr 0.000500 | ms/batch 422.92 | loss 0.62094 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time: 45.14s | valid loss 276.79 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  62 | lr 0.000500 | ms/batch 443.41 | loss 0.84205 |\n",
      "| epoch  62 | lr 0.000500 | ms/batch 502.21 | loss 0.75246 |\n",
      "| epoch  62 | lr 0.000500 | ms/batch 418.58 | loss 0.86278 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time: 47.38s | valid loss 272.43 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  63 | lr 0.000500 | ms/batch 362.18 | loss 0.77845 |\n",
      "| epoch  63 | lr 0.000500 | ms/batch 399.86 | loss 0.85034 |\n",
      "| epoch  63 | lr 0.000500 | ms/batch 405.07 | loss 0.78252 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time: 43.85s | valid loss 273.80 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  64 | lr 0.000500 | ms/batch 436.58 | loss 0.82546 |\n",
      "| epoch  64 | lr 0.000500 | ms/batch 336.10 | loss 0.94694 |\n",
      "| epoch  64 | lr 0.000500 | ms/batch 319.99 | loss 0.77247 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time: 41.88s | valid loss 270.68 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  65 | lr 0.000500 | ms/batch 342.58 | loss 0.94755 |\n",
      "| epoch  65 | lr 0.000500 | ms/batch 449.75 | loss 0.85071 |\n",
      "| epoch  65 | lr 0.000500 | ms/batch 371.66 | loss 0.69502 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time: 43.10s | valid loss 267.41 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  66 | lr 0.000500 | ms/batch 443.01 | loss 0.68718 |\n",
      "| epoch  66 | lr 0.000500 | ms/batch 372.45 | loss 0.70708 |\n",
      "| epoch  66 | lr 0.000500 | ms/batch 362.88 | loss 0.70078 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time: 43.48s | valid loss 263.94 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  67 | lr 0.000500 | ms/batch 359.34 | loss 0.73848 |\n",
      "| epoch  67 | lr 0.000500 | ms/batch 374.70 | loss 0.74155 |\n",
      "| epoch  67 | lr 0.000500 | ms/batch 361.51 | loss 0.71846 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time: 42.55s | valid loss 264.24 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  68 | lr 0.000500 | ms/batch 382.28 | loss 0.69887 |\n",
      "| epoch  68 | lr 0.000500 | ms/batch 411.40 | loss 0.82740 |\n",
      "| epoch  68 | lr 0.000500 | ms/batch 401.90 | loss 0.75813 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time: 44.02s | valid loss 260.32 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  69 | lr 0.000500 | ms/batch 380.03 | loss 0.72441 |\n",
      "| epoch  69 | lr 0.000500 | ms/batch 399.93 | loss 0.89377 |\n",
      "| epoch  69 | lr 0.000500 | ms/batch 401.08 | loss 0.73413 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time: 43.90s | valid loss 257.92 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  70 | lr 0.000500 | ms/batch 385.57 | loss 0.67402 |\n",
      "| epoch  70 | lr 0.000500 | ms/batch 369.51 | loss 0.65704 |\n",
      "| epoch  70 | lr 0.000500 | ms/batch 394.49 | loss 0.54200 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time: 43.24s | valid loss 258.90 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  71 | lr 0.000500 | ms/batch 496.72 | loss 0.84170 |\n",
      "| epoch  71 | lr 0.000500 | ms/batch 362.18 | loss 0.60510 |\n",
      "| epoch  71 | lr 0.000500 | ms/batch 381.48 | loss 0.70848 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time: 45.82s | valid loss 261.28 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  72 | lr 0.000500 | ms/batch 442.57 | loss 0.97420 |\n",
      "| epoch  72 | lr 0.000500 | ms/batch 396.99 | loss 0.61029 |\n",
      "| epoch  72 | lr 0.000500 | ms/batch 348.17 | loss 0.73314 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time: 44.01s | valid loss 260.34 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  73 | lr 0.000500 | ms/batch 374.75 | loss 0.71866 |\n",
      "| epoch  73 | lr 0.000500 | ms/batch 389.31 | loss 0.73392 |\n",
      "| epoch  73 | lr 0.000500 | ms/batch 379.83 | loss 0.64667 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time: 42.95s | valid loss 256.27 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  74 | lr 0.000500 | ms/batch 370.96 | loss 0.76438 |\n",
      "| epoch  74 | lr 0.000500 | ms/batch 416.34 | loss 0.79738 |\n",
      "| epoch  74 | lr 0.000500 | ms/batch 342.43 | loss 0.49133 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time: 42.94s | valid loss 256.74 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  75 | lr 0.000500 | ms/batch 439.08 | loss 0.77197 |\n",
      "| epoch  75 | lr 0.000500 | ms/batch 379.88 | loss 0.56348 |\n",
      "| epoch  75 | lr 0.000500 | ms/batch 387.41 | loss 0.82916 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time: 44.23s | valid loss 253.82 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  76 | lr 0.000500 | ms/batch 350.46 | loss 0.71400 |\n",
      "| epoch  76 | lr 0.000500 | ms/batch 356.20 | loss 0.69927 |\n",
      "| epoch  76 | lr 0.000500 | ms/batch 334.55 | loss 0.78597 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time: 40.34s | valid loss 251.06 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  77 | lr 0.000500 | ms/batch 439.67 | loss 0.55591 |\n",
      "| epoch  77 | lr 0.000500 | ms/batch 406.21 | loss 0.64275 |\n",
      "| epoch  77 | lr 0.000500 | ms/batch 378.29 | loss 0.62347 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time: 44.44s | valid loss 249.31 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  78 | lr 0.000500 | ms/batch 388.56 | loss 0.77395 |\n",
      "| epoch  78 | lr 0.000500 | ms/batch 430.90 | loss 0.74468 |\n",
      "| epoch  78 | lr 0.000500 | ms/batch 411.80 | loss 0.62493 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time: 44.33s | valid loss 245.42 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  79 | lr 0.000500 | ms/batch 372.30 | loss 0.45538 |\n",
      "| epoch  79 | lr 0.000500 | ms/batch 414.11 | loss 0.53143 |\n",
      "| epoch  79 | lr 0.000500 | ms/batch 356.70 | loss 0.59873 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time: 43.06s | valid loss 245.07 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  80 | lr 0.000500 | ms/batch 383.62 | loss 0.57594 |\n",
      "| epoch  80 | lr 0.000500 | ms/batch 402.67 | loss 0.73664 |\n",
      "| epoch  80 | lr 0.000500 | ms/batch 382.68 | loss 0.78619 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time: 43.41s | valid loss 246.16 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  81 | lr 0.000500 | ms/batch 448.30 | loss 0.53830 |\n",
      "| epoch  81 | lr 0.000500 | ms/batch 404.02 | loss 0.59424 |\n",
      "| epoch  81 | lr 0.000500 | ms/batch 386.47 | loss 0.79046 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time: 44.47s | valid loss 245.90 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  82 | lr 0.000500 | ms/batch 415.44 | loss 0.70662 |\n",
      "| epoch  82 | lr 0.000500 | ms/batch 435.78 | loss 0.63210 |\n",
      "| epoch  82 | lr 0.000500 | ms/batch 420.82 | loss 0.67377 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time: 45.66s | valid loss 243.08 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  83 | lr 0.000500 | ms/batch 562.42 | loss 0.68991 |\n",
      "| epoch  83 | lr 0.000500 | ms/batch 381.08 | loss 0.54633 |\n",
      "| epoch  83 | lr 0.000500 | ms/batch 442.12 | loss 0.39112 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time: 47.74s | valid loss 244.31 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  84 | lr 0.000500 | ms/batch 410.70 | loss 0.92758 |\n",
      "| epoch  84 | lr 0.000500 | ms/batch 371.41 | loss 0.78141 |\n",
      "| epoch  84 | lr 0.000500 | ms/batch 462.91 | loss 0.81049 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time: 44.87s | valid loss 243.54 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  85 | lr 0.000500 | ms/batch 425.81 | loss 0.52071 |\n",
      "| epoch  85 | lr 0.000500 | ms/batch 433.94 | loss 0.57230 |\n",
      "| epoch  85 | lr 0.000500 | ms/batch 387.51 | loss 0.67151 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time: 44.98s | valid loss 240.43 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  86 | lr 0.000500 | ms/batch 466.40 | loss 0.88590 |\n",
      "| epoch  86 | lr 0.000500 | ms/batch 470.54 | loss 0.53146 |\n",
      "| epoch  86 | lr 0.000500 | ms/batch 424.07 | loss 0.69458 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time: 47.21s | valid loss 238.09 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  87 | lr 0.000500 | ms/batch 395.34 | loss 0.65674 |\n",
      "| epoch  87 | lr 0.000500 | ms/batch 333.86 | loss 0.62364 |\n",
      "| epoch  87 | lr 0.000500 | ms/batch 379.14 | loss 0.61633 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time: 41.96s | valid loss 238.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  88 | lr 0.000500 | ms/batch 458.12 | loss 0.50675 |\n",
      "| epoch  88 | lr 0.000500 | ms/batch 410.50 | loss 0.61796 |\n",
      "| epoch  88 | lr 0.000500 | ms/batch 454.04 | loss 0.48364 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time: 46.99s | valid loss 236.61 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  89 | lr 0.000500 | ms/batch 393.35 | loss 0.66649 |\n",
      "| epoch  89 | lr 0.000500 | ms/batch 322.54 | loss 0.57255 |\n",
      "| epoch  89 | lr 0.000500 | ms/batch 433.64 | loss 0.59633 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time: 42.59s | valid loss 236.24 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  90 | lr 0.000500 | ms/batch 468.20 | loss 0.56850 |\n",
      "| epoch  90 | lr 0.000500 | ms/batch 356.50 | loss 0.65750 |\n",
      "| epoch  90 | lr 0.000500 | ms/batch 395.39 | loss 0.46469 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time: 44.19s | valid loss 237.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  91 | lr 0.000500 | ms/batch 462.86 | loss 0.55208 |\n",
      "| epoch  91 | lr 0.000500 | ms/batch 506.39 | loss 0.66305 |\n",
      "| epoch  91 | lr 0.000500 | ms/batch 374.30 | loss 0.82122 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time: 47.36s | valid loss 231.37 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  92 | lr 0.000500 | ms/batch 459.07 | loss 0.65522 |\n",
      "| epoch  92 | lr 0.000500 | ms/batch 399.58 | loss 0.42332 |\n",
      "| epoch  92 | lr 0.000500 | ms/batch 394.25 | loss 0.59445 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time: 44.51s | valid loss 230.91 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  93 | lr 0.000500 | ms/batch 380.58 | loss 0.64927 |\n",
      "| epoch  93 | lr 0.000500 | ms/batch 382.83 | loss 0.55418 |\n",
      "| epoch  93 | lr 0.000500 | ms/batch 427.95 | loss 0.62237 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time: 43.66s | valid loss 231.98 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  94 | lr 0.000500 | ms/batch 375.59 | loss 0.60798 |\n",
      "| epoch  94 | lr 0.000500 | ms/batch 397.44 | loss 0.52022 |\n",
      "| epoch  94 | lr 0.000500 | ms/batch 339.54 | loss 0.53645 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time: 42.28s | valid loss 229.62 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  95 | lr 0.000500 | ms/batch 440.02 | loss 0.58482 |\n",
      "| epoch  95 | lr 0.000500 | ms/batch 377.34 | loss 0.51303 |\n",
      "| epoch  95 | lr 0.000500 | ms/batch 403.32 | loss 0.48346 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time: 44.15s | valid loss 230.61 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  96 | lr 0.000500 | ms/batch 409.80 | loss 0.59719 |\n",
      "| epoch  96 | lr 0.000500 | ms/batch 497.72 | loss 0.65922 |\n",
      "| epoch  96 | lr 0.000500 | ms/batch 356.55 | loss 0.44308 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time: 45.14s | valid loss 229.41 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  97 | lr 0.000500 | ms/batch 401.92 | loss 0.59521 |\n",
      "| epoch  97 | lr 0.000500 | ms/batch 387.41 | loss 0.62595 |\n",
      "| epoch  97 | lr 0.000500 | ms/batch 434.39 | loss 0.54027 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time: 43.96s | valid loss 226.93 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  98 | lr 0.000500 | ms/batch 359.44 | loss 0.64043 |\n",
      "| epoch  98 | lr 0.000500 | ms/batch 492.63 | loss 0.57703 |\n",
      "| epoch  98 | lr 0.000500 | ms/batch 385.32 | loss 0.63354 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time: 44.08s | valid loss 227.70 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  99 | lr 0.000500 | ms/batch 411.00 | loss 0.75935 |\n",
      "| epoch  99 | lr 0.000500 | ms/batch 372.40 | loss 0.53136 |\n",
      "| epoch  99 | lr 0.000500 | ms/batch 385.42 | loss 0.56875 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time: 43.27s | valid loss 225.28 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 100 | lr 0.000500 | ms/batch 460.87 | loss 0.45511 |\n",
      "| epoch 100 | lr 0.000500 | ms/batch 385.92 | loss 0.53882 |\n",
      "| epoch 100 | lr 0.000500 | ms/batch 401.28 | loss 0.74621 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time: 44.77s | valid loss 226.56 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 101 | lr 0.000500 | ms/batch 440.07 | loss 0.57099 |\n",
      "| epoch 101 | lr 0.000500 | ms/batch 440.57 | loss 0.72194 |\n",
      "| epoch 101 | lr 0.000500 | ms/batch 440.57 | loss 0.65714 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 101 | time: 46.16s | valid loss 224.49 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 102 | lr 0.000500 | ms/batch 372.05 | loss 0.54069 |\n",
      "| epoch 102 | lr 0.000500 | ms/batch 429.80 | loss 0.54287 |\n",
      "| epoch 102 | lr 0.000500 | ms/batch 442.02 | loss 0.43901 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 102 | time: 45.11s | valid loss 224.56 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 103 | lr 0.000500 | ms/batch 422.57 | loss 0.49931 |\n",
      "| epoch 103 | lr 0.000500 | ms/batch 438.38 | loss 0.60529 |\n",
      "| epoch 103 | lr 0.000500 | ms/batch 333.51 | loss 0.37936 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 103 | time: 43.68s | valid loss 223.22 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 104 | lr 0.000500 | ms/batch 401.03 | loss 0.47407 |\n",
      "| epoch 104 | lr 0.000500 | ms/batch 337.25 | loss 0.68770 |\n",
      "| epoch 104 | lr 0.000500 | ms/batch 338.29 | loss 0.60793 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 104 | time: 41.29s | valid loss 223.39 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 105 | lr 0.000500 | ms/batch 376.59 | loss 0.51219 |\n",
      "| epoch 105 | lr 0.000500 | ms/batch 377.79 | loss 0.49954 |\n",
      "| epoch 105 | lr 0.000500 | ms/batch 376.19 | loss 0.55349 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 105 | time: 42.46s | valid loss 221.64 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 106 | lr 0.000500 | ms/batch 430.95 | loss 0.46343 |\n",
      "| epoch 106 | lr 0.000500 | ms/batch 445.06 | loss 0.40245 |\n",
      "| epoch 106 | lr 0.000500 | ms/batch 510.93 | loss 0.47966 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 106 | time: 47.38s | valid loss 220.50 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 107 | lr 0.000500 | ms/batch 466.20 | loss 0.63485 |\n",
      "| epoch 107 | lr 0.000500 | ms/batch 518.91 | loss 0.51349 |\n",
      "| epoch 107 | lr 0.000500 | ms/batch 496.02 | loss 0.39641 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 107 | time: 49.61s | valid loss 220.51 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 108 | lr 0.000500 | ms/batch 395.44 | loss 0.63661 |\n",
      "| epoch 108 | lr 0.000500 | ms/batch 404.62 | loss 0.30140 |\n",
      "| epoch 108 | lr 0.000500 | ms/batch 399.68 | loss 0.63039 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 108 | time: 43.77s | valid loss 218.64 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 109 | lr 0.000500 | ms/batch 356.99 | loss 0.55620 |\n",
      "| epoch 109 | lr 0.000500 | ms/batch 329.57 | loss 0.45565 |\n",
      "| epoch 109 | lr 0.000500 | ms/batch 359.79 | loss 0.60725 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 109 | time: 40.92s | valid loss 214.65 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 110 | lr 0.000500 | ms/batch 482.46 | loss 0.59474 |\n",
      "| epoch 110 | lr 0.000500 | ms/batch 417.58 | loss 0.45475 |\n",
      "| epoch 110 | lr 0.000500 | ms/batch 474.23 | loss 0.45301 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 110 | time: 48.22s | valid loss 213.63 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 111 | lr 0.000500 | ms/batch 492.78 | loss 0.54459 |\n",
      "| epoch 111 | lr 0.000500 | ms/batch 461.27 | loss 0.39762 |\n",
      "| epoch 111 | lr 0.000500 | ms/batch 556.61 | loss 0.52144 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 111 | time: 50.40s | valid loss 212.62 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 112 | lr 0.000500 | ms/batch 400.03 | loss 0.56374 |\n",
      "| epoch 112 | lr 0.000500 | ms/batch 556.11 | loss 0.46872 |\n",
      "| epoch 112 | lr 0.000500 | ms/batch 465.01 | loss 0.37675 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 112 | time: 49.07s | valid loss 211.00 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 113 | lr 0.000500 | ms/batch 347.77 | loss 0.55382 |\n",
      "| epoch 113 | lr 0.000500 | ms/batch 425.66 | loss 0.46325 |\n",
      "| epoch 113 | lr 0.000500 | ms/batch 469.24 | loss 0.57309 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 113 | time: 44.91s | valid loss 208.82 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 114 | lr 0.000500 | ms/batch 444.56 | loss 0.46126 |\n",
      "| epoch 114 | lr 0.000500 | ms/batch 440.62 | loss 0.49303 |\n",
      "| epoch 114 | lr 0.000500 | ms/batch 373.55 | loss 0.59689 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 114 | time: 45.16s | valid loss 208.86 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 115 | lr 0.000500 | ms/batch 431.50 | loss 0.39229 |\n",
      "| epoch 115 | lr 0.000500 | ms/batch 415.79 | loss 0.49238 |\n",
      "| epoch 115 | lr 0.000500 | ms/batch 473.18 | loss 0.43054 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 115 | time: 46.40s | valid loss 207.71 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 116 | lr 0.000500 | ms/batch 523.45 | loss 0.45536 |\n",
      "| epoch 116 | lr 0.000500 | ms/batch 402.97 | loss 0.51554 |\n",
      "| epoch 116 | lr 0.000500 | ms/batch 396.54 | loss 0.42646 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 116 | time: 46.22s | valid loss 207.99 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 117 | lr 0.000500 | ms/batch 458.27 | loss 0.46276 |\n",
      "| epoch 117 | lr 0.000500 | ms/batch 393.47 | loss 0.38192 |\n",
      "| epoch 117 | lr 0.000500 | ms/batch 354.85 | loss 0.46817 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 117 | time: 44.20s | valid loss 206.02 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 118 | lr 0.000500 | ms/batch 392.30 | loss 0.50602 |\n",
      "| epoch 118 | lr 0.000500 | ms/batch 430.60 | loss 0.39868 |\n",
      "| epoch 118 | lr 0.000500 | ms/batch 369.76 | loss 0.47855 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 118 | time: 43.80s | valid loss 207.25 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 119 | lr 0.000500 | ms/batch 403.27 | loss 0.46735 |\n",
      "| epoch 119 | lr 0.000500 | ms/batch 458.17 | loss 0.44156 |\n",
      "| epoch 119 | lr 0.000500 | ms/batch 343.73 | loss 0.56171 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 119 | time: 44.20s | valid loss 204.45 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 120 | lr 0.000500 | ms/batch 396.44 | loss 0.63606 |\n",
      "| epoch 120 | lr 0.000500 | ms/batch 434.04 | loss 0.56071 |\n",
      "| epoch 120 | lr 0.000500 | ms/batch 438.03 | loss 0.54617 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 120 | time: 45.82s | valid loss 206.69 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 121 | lr 0.000500 | ms/batch 412.85 | loss 0.46705 |\n",
      "| epoch 121 | lr 0.000500 | ms/batch 495.92 | loss 0.34813 |\n",
      "| epoch 121 | lr 0.000500 | ms/batch 440.92 | loss 0.60096 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 121 | time: 47.17s | valid loss 202.08 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 122 | lr 0.000500 | ms/batch 414.59 | loss 0.55747 |\n",
      "| epoch 122 | lr 0.000500 | ms/batch 594.81 | loss 0.41163 |\n",
      "| epoch 122 | lr 0.000500 | ms/batch 470.29 | loss 0.47498 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 122 | time: 49.94s | valid loss 204.79 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 123 | lr 0.000500 | ms/batch 451.99 | loss 0.47255 |\n",
      "| epoch 123 | lr 0.000500 | ms/batch 372.40 | loss 0.48982 |\n",
      "| epoch 123 | lr 0.000500 | ms/batch 406.81 | loss 0.64029 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 123 | time: 44.88s | valid loss 203.83 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 124 | lr 0.000500 | ms/batch 526.79 | loss 0.52971 |\n",
      "| epoch 124 | lr 0.000500 | ms/batch 362.76 | loss 0.50400 |\n",
      "| epoch 124 | lr 0.000500 | ms/batch 353.45 | loss 0.51433 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 124 | time: 44.70s | valid loss 203.41 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 125 | lr 0.000500 | ms/batch 436.08 | loss 0.41852 |\n",
      "| epoch 125 | lr 0.000500 | ms/batch 442.52 | loss 0.35760 |\n",
      "| epoch 125 | lr 0.000500 | ms/batch 417.88 | loss 0.36854 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 125 | time: 46.53s | valid loss 203.57 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 126 | lr 0.000500 | ms/batch 462.21 | loss 0.35991 |\n",
      "| epoch 126 | lr 0.000500 | ms/batch 383.92 | loss 0.37576 |\n",
      "| epoch 126 | lr 0.000500 | ms/batch 395.19 | loss 0.35844 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 126 | time: 45.65s | valid loss 202.08 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 127 | lr 0.000500 | ms/batch 415.24 | loss 0.55444 |\n",
      "| epoch 127 | lr 0.000500 | ms/batch 362.98 | loss 0.52490 |\n",
      "| epoch 127 | lr 0.000500 | ms/batch 370.16 | loss 0.25167 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 127 | time: 42.94s | valid loss 200.64 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 128 | lr 0.000500 | ms/batch 375.79 | loss 0.39558 |\n",
      "| epoch 128 | lr 0.000500 | ms/batch 477.97 | loss 0.37862 |\n",
      "| epoch 128 | lr 0.000500 | ms/batch 474.53 | loss 0.26728 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 128 | time: 46.72s | valid loss 201.27 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 129 | lr 0.000500 | ms/batch 420.28 | loss 0.40229 |\n",
      "| epoch 129 | lr 0.000500 | ms/batch 432.74 | loss 0.38033 |\n",
      "| epoch 129 | lr 0.000500 | ms/batch 444.06 | loss 0.39348 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 129 | time: 46.01s | valid loss 198.74 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 130 | lr 0.000500 | ms/batch 413.89 | loss 0.43244 |\n",
      "| epoch 130 | lr 0.000500 | ms/batch 431.79 | loss 0.54476 |\n",
      "| epoch 130 | lr 0.000500 | ms/batch 389.71 | loss 0.42755 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 130 | time: 45.19s | valid loss 201.81 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 131 | lr 0.000500 | ms/batch 427.01 | loss 0.49424 |\n",
      "| epoch 131 | lr 0.000500 | ms/batch 440.07 | loss 0.39889 |\n",
      "| epoch 131 | lr 0.000500 | ms/batch 415.84 | loss 0.55312 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 131 | time: 45.44s | valid loss 196.02 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 132 | lr 0.000500 | ms/batch 418.13 | loss 0.47342 |\n",
      "| epoch 132 | lr 0.000500 | ms/batch 376.04 | loss 0.40647 |\n",
      "| epoch 132 | lr 0.000500 | ms/batch 453.09 | loss 0.45192 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 132 | time: 44.66s | valid loss 194.40 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 133 | lr 0.000500 | ms/batch 407.56 | loss 0.28351 |\n",
      "| epoch 133 | lr 0.000500 | ms/batch 383.57 | loss 0.53876 |\n",
      "| epoch 133 | lr 0.000500 | ms/batch 390.90 | loss 0.38824 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 133 | time: 43.60s | valid loss 195.41 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 134 | lr 0.000500 | ms/batch 401.92 | loss 0.54933 |\n",
      "| epoch 134 | lr 0.000500 | ms/batch 343.78 | loss 0.41119 |\n",
      "| epoch 134 | lr 0.000500 | ms/batch 431.25 | loss 0.45864 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 134 | time: 43.18s | valid loss 195.16 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 135 | lr 0.000500 | ms/batch 446.75 | loss 0.30550 |\n",
      "| epoch 135 | lr 0.000500 | ms/batch 415.19 | loss 0.36717 |\n",
      "| epoch 135 | lr 0.000500 | ms/batch 387.51 | loss 0.46640 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 135 | time: 44.59s | valid loss 194.64 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 136 | lr 0.000500 | ms/batch 355.10 | loss 0.39127 |\n",
      "| epoch 136 | lr 0.000500 | ms/batch 395.14 | loss 0.50313 |\n",
      "| epoch 136 | lr 0.000500 | ms/batch 409.70 | loss 0.43777 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 136 | time: 42.77s | valid loss 196.31 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 137 | lr 0.000500 | ms/batch 409.25 | loss 0.46663 |\n",
      "| epoch 137 | lr 0.000500 | ms/batch 372.20 | loss 0.31481 |\n",
      "| epoch 137 | lr 0.000500 | ms/batch 389.76 | loss 0.46299 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 137 | time: 43.27s | valid loss 196.55 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 138 | lr 0.000500 | ms/batch 521.11 | loss 0.55073 |\n",
      "| epoch 138 | lr 0.000500 | ms/batch 485.20 | loss 0.42320 |\n",
      "| epoch 138 | lr 0.000500 | ms/batch 417.48 | loss 0.35491 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 138 | time: 48.58s | valid loss 193.62 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 139 | lr 0.000500 | ms/batch 440.62 | loss 0.30943 |\n",
      "| epoch 139 | lr 0.000500 | ms/batch 458.37 | loss 0.28942 |\n",
      "| epoch 139 | lr 0.000500 | ms/batch 394.89 | loss 0.23138 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 139 | time: 45.84s | valid loss 195.90 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 140 | lr 0.000500 | ms/batch 456.33 | loss 0.35584 |\n",
      "| epoch 140 | lr 0.000500 | ms/batch 446.41 | loss 0.40410 |\n",
      "| epoch 140 | lr 0.000500 | ms/batch 388.51 | loss 0.74612 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 140 | time: 46.66s | valid loss 194.06 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 141 | lr 0.000500 | ms/batch 420.42 | loss 0.45145 |\n",
      "| epoch 141 | lr 0.000500 | ms/batch 379.58 | loss 0.43998 |\n",
      "| epoch 141 | lr 0.000500 | ms/batch 415.99 | loss 0.31830 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 141 | time: 44.16s | valid loss 193.75 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 142 | lr 0.000500 | ms/batch 437.03 | loss 0.40292 |\n",
      "| epoch 142 | lr 0.000500 | ms/batch 403.42 | loss 0.31630 |\n",
      "| epoch 142 | lr 0.000500 | ms/batch 431.59 | loss 0.52055 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 142 | time: 45.38s | valid loss 192.74 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 143 | lr 0.000500 | ms/batch 393.55 | loss 0.37110 |\n",
      "| epoch 143 | lr 0.000500 | ms/batch 427.71 | loss 0.56234 |\n",
      "| epoch 143 | lr 0.000500 | ms/batch 447.35 | loss 0.35534 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 143 | time: 44.83s | valid loss 190.43 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 144 | lr 0.000500 | ms/batch 342.33 | loss 0.44776 |\n",
      "| epoch 144 | lr 0.000500 | ms/batch 401.28 | loss 0.38509 |\n",
      "| epoch 144 | lr 0.000500 | ms/batch 456.18 | loss 0.42963 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 144 | time: 43.94s | valid loss 192.19 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 145 | lr 0.000500 | ms/batch 485.15 | loss 0.36624 |\n",
      "| epoch 145 | lr 0.000500 | ms/batch 408.31 | loss 0.39801 |\n",
      "| epoch 145 | lr 0.000500 | ms/batch 456.53 | loss 0.44616 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 145 | time: 46.43s | valid loss 190.93 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 146 | lr 0.000500 | ms/batch 413.04 | loss 0.41981 |\n",
      "| epoch 146 | lr 0.000500 | ms/batch 419.63 | loss 0.29961 |\n",
      "| epoch 146 | lr 0.000500 | ms/batch 353.30 | loss 0.45288 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 146 | time: 43.47s | valid loss 192.95 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 147 | lr 0.000500 | ms/batch 466.20 | loss 0.56836 |\n",
      "| epoch 147 | lr 0.000500 | ms/batch 434.09 | loss 0.32764 |\n",
      "| epoch 147 | lr 0.000500 | ms/batch 472.29 | loss 0.43006 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 147 | time: 47.05s | valid loss 191.43 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 148 | lr 0.000500 | ms/batch 459.52 | loss 0.41618 |\n",
      "| epoch 148 | lr 0.000500 | ms/batch 389.81 | loss 0.29239 |\n",
      "| epoch 148 | lr 0.000500 | ms/batch 372.05 | loss 0.46769 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 148 | time: 44.54s | valid loss 189.31 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 149 | lr 0.000500 | ms/batch 458.32 | loss 0.39646 |\n",
      "| epoch 149 | lr 0.000500 | ms/batch 429.65 | loss 0.34213 |\n",
      "| epoch 149 | lr 0.000500 | ms/batch 394.74 | loss 0.34343 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 149 | time: 46.19s | valid loss 190.93 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 150 | lr 0.000500 | ms/batch 431.25 | loss 0.36951 |\n",
      "| epoch 150 | lr 0.000500 | ms/batch 401.23 | loss 0.40785 |\n",
      "| epoch 150 | lr 0.000500 | ms/batch 397.59 | loss 0.45903 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 150 | time: 44.83s | valid loss 187.55 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 151 | lr 0.000500 | ms/batch 459.22 | loss 0.41240 |\n",
      "| epoch 151 | lr 0.000500 | ms/batch 355.95 | loss 0.38940 |\n",
      "| epoch 151 | lr 0.000500 | ms/batch 409.85 | loss 0.26109 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 151 | time: 44.41s | valid loss 185.18 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 152 | lr 0.000500 | ms/batch 430.40 | loss 0.46611 |\n",
      "| epoch 152 | lr 0.000500 | ms/batch 335.45 | loss 0.30023 |\n",
      "| epoch 152 | lr 0.000500 | ms/batch 433.09 | loss 0.28196 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 152 | time: 43.67s | valid loss 186.69 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 153 | lr 0.000500 | ms/batch 463.50 | loss 0.54260 |\n",
      "| epoch 153 | lr 0.000500 | ms/batch 468.83 | loss 0.23875 |\n",
      "| epoch 153 | lr 0.000500 | ms/batch 504.61 | loss 0.30186 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 153 | time: 49.88s | valid loss 186.69 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 154 | lr 0.000500 | ms/batch 537.66 | loss 0.43367 |\n",
      "| epoch 154 | lr 0.000500 | ms/batch 405.02 | loss 0.47320 |\n",
      "| epoch 154 | lr 0.000500 | ms/batch 378.24 | loss 0.30804 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 154 | time: 47.34s | valid loss 183.81 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 155 | lr 0.000500 | ms/batch 455.08 | loss 0.38284 |\n",
      "| epoch 155 | lr 0.000500 | ms/batch 459.72 | loss 0.45382 |\n",
      "| epoch 155 | lr 0.000500 | ms/batch 392.90 | loss 0.32234 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 155 | time: 45.75s | valid loss 184.48 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 156 | lr 0.000500 | ms/batch 392.60 | loss 0.30118 |\n",
      "| epoch 156 | lr 0.000500 | ms/batch 461.62 | loss 0.24856 |\n",
      "| epoch 156 | lr 0.000500 | ms/batch 355.65 | loss 0.31860 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 156 | time: 44.35s | valid loss 184.29 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 157 | lr 0.000500 | ms/batch 431.89 | loss 0.30979 |\n",
      "| epoch 157 | lr 0.000500 | ms/batch 372.00 | loss 0.26921 |\n",
      "| epoch 157 | lr 0.000500 | ms/batch 429.80 | loss 0.30057 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 157 | time: 44.39s | valid loss 182.91 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 158 | lr 0.000500 | ms/batch 427.01 | loss 0.26115 |\n",
      "| epoch 158 | lr 0.000500 | ms/batch 381.53 | loss 0.42290 |\n",
      "| epoch 158 | lr 0.000500 | ms/batch 390.31 | loss 0.36497 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 158 | time: 44.38s | valid loss 184.83 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 159 | lr 0.000500 | ms/batch 426.86 | loss 0.37624 |\n",
      "| epoch 159 | lr 0.000500 | ms/batch 392.35 | loss 0.33404 |\n",
      "| epoch 159 | lr 0.000500 | ms/batch 391.40 | loss 0.26697 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 159 | time: 43.63s | valid loss 184.76 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 160 | lr 0.000500 | ms/batch 377.34 | loss 0.36342 |\n",
      "| epoch 160 | lr 0.000500 | ms/batch 477.67 | loss 0.35965 |\n",
      "| epoch 160 | lr 0.000500 | ms/batch 450.74 | loss 0.28547 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 160 | time: 45.98s | valid loss 181.11 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 161 | lr 0.000500 | ms/batch 444.16 | loss 0.25984 |\n",
      "| epoch 161 | lr 0.000500 | ms/batch 408.66 | loss 0.25359 |\n",
      "| epoch 161 | lr 0.000500 | ms/batch 381.53 | loss 0.17943 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 161 | time: 44.48s | valid loss 181.67 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 162 | lr 0.000500 | ms/batch 475.58 | loss 0.35968 |\n",
      "| epoch 162 | lr 0.000500 | ms/batch 408.81 | loss 0.37550 |\n",
      "| epoch 162 | lr 0.000500 | ms/batch 404.27 | loss 0.27289 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 162 | time: 45.67s | valid loss 182.93 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 163 | lr 0.000500 | ms/batch 405.86 | loss 0.35765 |\n",
      "| epoch 163 | lr 0.000500 | ms/batch 391.90 | loss 0.24368 |\n",
      "| epoch 163 | lr 0.000500 | ms/batch 360.14 | loss 0.38604 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 163 | time: 43.50s | valid loss 181.30 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 164 | lr 0.000500 | ms/batch 415.59 | loss 0.26134 |\n",
      "| epoch 164 | lr 0.000500 | ms/batch 408.76 | loss 0.34504 |\n",
      "| epoch 164 | lr 0.000500 | ms/batch 372.70 | loss 0.37474 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 164 | time: 43.94s | valid loss 180.24 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 165 | lr 0.000500 | ms/batch 536.71 | loss 0.31182 |\n",
      "| epoch 165 | lr 0.000500 | ms/batch 545.19 | loss 0.50511 |\n",
      "| epoch 165 | lr 0.000500 | ms/batch 480.91 | loss 0.54685 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 165 | time: 51.27s | valid loss 181.34 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 166 | lr 0.000500 | ms/batch 381.88 | loss 0.40563 |\n",
      "| epoch 166 | lr 0.000500 | ms/batch 383.77 | loss 0.33698 |\n",
      "| epoch 166 | lr 0.000500 | ms/batch 368.96 | loss 0.35657 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 166 | time: 42.82s | valid loss 181.13 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 167 | lr 0.000500 | ms/batch 429.65 | loss 0.38250 |\n",
      "| epoch 167 | lr 0.000500 | ms/batch 380.88 | loss 0.40504 |\n",
      "| epoch 167 | lr 0.000500 | ms/batch 393.60 | loss 0.43748 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 167 | time: 44.40s | valid loss 179.98 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 168 | lr 0.000500 | ms/batch 441.12 | loss 0.33922 |\n",
      "| epoch 168 | lr 0.000500 | ms/batch 504.40 | loss 0.27759 |\n",
      "| epoch 168 | lr 0.000500 | ms/batch 494.73 | loss 0.21641 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 168 | time: 49.01s | valid loss 181.79 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 169 | lr 0.000500 | ms/batch 503.03 | loss 0.40395 |\n",
      "| epoch 169 | lr 0.000500 | ms/batch 407.81 | loss 0.34590 |\n",
      "| epoch 169 | lr 0.000500 | ms/batch 448.35 | loss 0.40733 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 169 | time: 47.00s | valid loss 180.50 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 170 | lr 0.000500 | ms/batch 454.63 | loss 0.31765 |\n",
      "| epoch 170 | lr 0.000500 | ms/batch 434.49 | loss 0.30033 |\n",
      "| epoch 170 | lr 0.000500 | ms/batch 453.44 | loss 0.25790 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 170 | time: 47.07s | valid loss 178.69 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 171 | lr 0.000500 | ms/batch 461.27 | loss 0.48408 |\n",
      "| epoch 171 | lr 0.000500 | ms/batch 389.16 | loss 0.29249 |\n",
      "| epoch 171 | lr 0.000500 | ms/batch 419.03 | loss 0.31549 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 171 | time: 45.23s | valid loss 179.85 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 172 | lr 0.000500 | ms/batch 429.45 | loss 0.39740 |\n",
      "| epoch 172 | lr 0.000500 | ms/batch 494.48 | loss 0.22967 |\n",
      "| epoch 172 | lr 0.000500 | ms/batch 359.29 | loss 0.29326 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 172 | time: 46.46s | valid loss 179.78 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 173 | lr 0.000500 | ms/batch 465.85 | loss 0.19240 |\n",
      "| epoch 173 | lr 0.000500 | ms/batch 375.50 | loss 0.24520 |\n",
      "| epoch 173 | lr 0.000500 | ms/batch 414.59 | loss 0.29756 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 173 | time: 45.41s | valid loss 180.08 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 174 | lr 0.000500 | ms/batch 363.83 | loss 0.39656 |\n",
      "| epoch 174 | lr 0.000500 | ms/batch 383.46 | loss 0.37409 |\n",
      "| epoch 174 | lr 0.000500 | ms/batch 421.92 | loss 0.31732 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 174 | time: 43.97s | valid loss 180.17 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 175 | lr 0.000500 | ms/batch 431.69 | loss 0.21306 |\n",
      "| epoch 175 | lr 0.000500 | ms/batch 421.54 | loss 0.21838 |\n",
      "| epoch 175 | lr 0.000500 | ms/batch 433.52 | loss 0.32654 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 175 | time: 45.92s | valid loss 180.40 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 176 | lr 0.000500 | ms/batch 449.35 | loss 0.25604 |\n",
      "| epoch 176 | lr 0.000500 | ms/batch 346.62 | loss 0.39057 |\n",
      "| epoch 176 | lr 0.000500 | ms/batch 382.23 | loss 0.44949 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 176 | time: 44.36s | valid loss 182.91 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 177 | lr 0.000500 | ms/batch 426.61 | loss 0.29880 |\n",
      "| epoch 177 | lr 0.000500 | ms/batch 444.51 | loss 0.24039 |\n",
      "| epoch 177 | lr 0.000500 | ms/batch 396.19 | loss 0.32051 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 177 | time: 45.34s | valid loss 182.27 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 178 | lr 0.000500 | ms/batch 448.30 | loss 0.30181 |\n",
      "| epoch 178 | lr 0.000500 | ms/batch 457.43 | loss 0.31394 |\n",
      "| epoch 178 | lr 0.000500 | ms/batch 430.80 | loss 0.34419 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 178 | time: 46.84s | valid loss 180.09 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 179 | lr 0.000500 | ms/batch 480.69 | loss 0.28181 |\n",
      "| epoch 179 | lr 0.000500 | ms/batch 447.60 | loss 0.30080 |\n",
      "| epoch 179 | lr 0.000500 | ms/batch 448.80 | loss 0.24800 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 179 | time: 47.42s | valid loss 179.39 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 180 | lr 0.000500 | ms/batch 438.93 | loss 0.41120 |\n",
      "| epoch 180 | lr 0.000500 | ms/batch 402.02 | loss 0.37884 |\n",
      "| epoch 180 | lr 0.000500 | ms/batch 386.32 | loss 0.30962 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 180 | time: 44.68s | valid loss 180.39 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 181 | lr 0.000500 | ms/batch 456.18 | loss 0.29806 |\n",
      "| epoch 181 | lr 0.000500 | ms/batch 439.62 | loss 0.26197 |\n",
      "| epoch 181 | lr 0.000500 | ms/batch 512.73 | loss 0.24158 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 181 | time: 47.96s | valid loss 178.99 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 182 | lr 0.000500 | ms/batch 453.14 | loss 0.28396 |\n",
      "| epoch 182 | lr 0.000500 | ms/batch 468.50 | loss 0.48154 |\n",
      "| epoch 182 | lr 0.000500 | ms/batch 412.65 | loss 0.25728 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 182 | time: 47.24s | valid loss 178.83 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 183 | lr 0.000500 | ms/batch 489.79 | loss 0.36846 |\n",
      "| epoch 183 | lr 0.000500 | ms/batch 456.40 | loss 0.38805 |\n",
      "| epoch 183 | lr 0.000500 | ms/batch 461.56 | loss 0.25941 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 183 | time: 48.35s | valid loss 177.47 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 184 | lr 0.000500 | ms/batch 430.60 | loss 0.30410 |\n",
      "| epoch 184 | lr 0.000500 | ms/batch 413.09 | loss 0.27585 |\n",
      "| epoch 184 | lr 0.000500 | ms/batch 434.49 | loss 0.20168 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 184 | time: 45.38s | valid loss 177.07 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 185 | lr 0.000500 | ms/batch 425.81 | loss 0.34764 |\n",
      "| epoch 185 | lr 0.000500 | ms/batch 465.30 | loss 0.26346 |\n",
      "| epoch 185 | lr 0.000500 | ms/batch 364.33 | loss 0.29921 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 185 | time: 45.12s | valid loss 179.26 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 186 | lr 0.000500 | ms/batch 416.83 | loss 0.17691 |\n",
      "| epoch 186 | lr 0.000500 | ms/batch 428.85 | loss 0.24060 |\n",
      "| epoch 186 | lr 0.000500 | ms/batch 433.19 | loss 0.25808 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 186 | time: 45.47s | valid loss 178.77 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 187 | lr 0.000500 | ms/batch 417.68 | loss 0.29346 |\n",
      "| epoch 187 | lr 0.000500 | ms/batch 434.49 | loss 0.20984 |\n",
      "| epoch 187 | lr 0.000500 | ms/batch 443.46 | loss 0.24516 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 187 | time: 46.04s | valid loss 178.24 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 188 | lr 0.000500 | ms/batch 459.07 | loss 0.21722 |\n",
      "| epoch 188 | lr 0.000500 | ms/batch 394.25 | loss 0.29920 |\n",
      "| epoch 188 | lr 0.000500 | ms/batch 394.24 | loss 0.18604 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 188 | time: 45.06s | valid loss 177.92 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 189 | lr 0.000500 | ms/batch 501.61 | loss 0.25531 |\n",
      "| epoch 189 | lr 0.000500 | ms/batch 376.89 | loss 0.26517 |\n",
      "| epoch 189 | lr 0.000500 | ms/batch 433.59 | loss 0.28368 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 189 | time: 46.39s | valid loss 178.24 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 190 | lr 0.000500 | ms/batch 440.12 | loss 0.30585 |\n",
      "| epoch 190 | lr 0.000500 | ms/batch 442.86 | loss 0.30353 |\n",
      "| epoch 190 | lr 0.000500 | ms/batch 407.66 | loss 0.34321 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 190 | time: 45.98s | valid loss 176.68 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 191 | lr 0.000500 | ms/batch 499.56 | loss 0.20377 |\n",
      "| epoch 191 | lr 0.000500 | ms/batch 343.58 | loss 0.44722 |\n",
      "| epoch 191 | lr 0.000500 | ms/batch 404.87 | loss 0.30737 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 191 | time: 44.88s | valid loss 177.81 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 192 | lr 0.000500 | ms/batch 387.61 | loss 0.45434 |\n",
      "| epoch 192 | lr 0.000500 | ms/batch 495.08 | loss 0.22151 |\n",
      "| epoch 192 | lr 0.000500 | ms/batch 409.45 | loss 0.20795 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 192 | time: 45.71s | valid loss 179.16 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 193 | lr 0.000500 | ms/batch 428.00 | loss 0.31487 |\n",
      "| epoch 193 | lr 0.000500 | ms/batch 388.66 | loss 0.26876 |\n",
      "| epoch 193 | lr 0.000500 | ms/batch 398.98 | loss 0.30733 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 193 | time: 44.64s | valid loss 177.75 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 194 | lr 0.000500 | ms/batch 436.73 | loss 0.28920 |\n",
      "| epoch 194 | lr 0.000500 | ms/batch 384.72 | loss 0.30485 |\n",
      "| epoch 194 | lr 0.000500 | ms/batch 392.05 | loss 0.38272 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 194 | time: 44.81s | valid loss 175.49 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 195 | lr 0.000500 | ms/batch 419.43 | loss 0.22582 |\n",
      "| epoch 195 | lr 0.000500 | ms/batch 441.67 | loss 0.27649 |\n",
      "| epoch 195 | lr 0.000500 | ms/batch 424.91 | loss 0.36900 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 195 | time: 46.39s | valid loss 173.59 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 196 | lr 0.000500 | ms/batch 380.23 | loss 0.25287 |\n",
      "| epoch 196 | lr 0.000500 | ms/batch 519.16 | loss 0.28911 |\n",
      "| epoch 196 | lr 0.000500 | ms/batch 466.85 | loss 0.28866 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 196 | time: 47.02s | valid loss 172.58 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 197 | lr 0.000500 | ms/batch 397.14 | loss 0.41192 |\n",
      "| epoch 197 | lr 0.000500 | ms/batch 435.73 | loss 0.12596 |\n",
      "| epoch 197 | lr 0.000500 | ms/batch 442.27 | loss 0.25914 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 197 | time: 45.36s | valid loss 172.61 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 198 | lr 0.000500 | ms/batch 463.44 | loss 0.21537 |\n",
      "| epoch 198 | lr 0.000500 | ms/batch 488.19 | loss 0.20188 |\n",
      "| epoch 198 | lr 0.000500 | ms/batch 438.53 | loss 0.19760 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 198 | time: 48.14s | valid loss 173.79 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 199 | lr 0.000500 | ms/batch 401.13 | loss 0.32659 |\n",
      "| epoch 199 | lr 0.000500 | ms/batch 480.86 | loss 0.31941 |\n",
      "| epoch 199 | lr 0.000500 | ms/batch 511.48 | loss 0.21699 |\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 199 | time: 48.71s | valid loss 172.85 | \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "for epoch in range(EPOCHES):  # again, normally you would NOT do 300 epochs, it is toy data    \n",
    "    training_batch = training_batch_data[epoch]\n",
    "    epoch_start_time = time.time()\n",
    "    train(model,training_batch,to_ix_w,to_ix_l)\n",
    "    val_loss = evaluate(model, test_batch_data,to_ix_w,to_ix_l)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss))\n",
    "    print('-' * 89)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存储数据\n",
    "import os\n",
    "torch.save(best_model.state_dict(), os.path.join(os.getcwd(),\"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存储用户字典\n",
    "with open(os.path.join(os.getcwd(),\"user_dict.txt\"),\"w\",encoding=\"utf-8\") as ud:\n",
    "    ud.write(str(list(user_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#存储word_id表\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "class JsonEncoder(json.JSONEncoder):\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, datetime):                                 \n",
    "            return obj.__str__()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)\n",
    "\n",
    "def save_dict(filename, dic):\n",
    "    '''save dict into json file'''\n",
    "    with open(filename,'w',encoding=\"utf-8\") as json_file:\n",
    "        json.dump(dic, json_file, ensure_ascii=False, cls=JsonEncoder)\n",
    "        \n",
    "def load_dict(filename):\n",
    "    '''load dict from json file'''\n",
    "    with open(filename,\"r\",encoding=\"utf-8\") as json_file:\n",
    "\t    dic = json.load(json_file)\n",
    "    return dic\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict(os.path.join(os.getcwd(),\"word_id.txt\"),to_ix_w)\n",
    "save_dict(os.path.join(os.getcwd(),\"tag_id.txt\"),to_ix_l)\n",
    "#存储最优model\n",
    "#evalue\n",
    "#读取数据\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (word_embeds): Embedding(32915, 300)\n",
       "  (lstm): LSTM(300, 250, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=500, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 500\n",
    "to_ix_w = load_dict(os.path.join(os.getcwd(),\"word_id.txt\"))\n",
    "to_ix_l = load_dict(os.path.join(os.getcwd(),\"tag_id.txt\"))\n",
    "OrderedDict = torch.load(os.path.join(os.getcwd(),\"model\"))\n",
    "len_ = len(OrderedDict[\"word_embeds.weight\"])\n",
    "to_l_ix = {v: k for k, v in to_ix_l.items()}\n",
    "model = BiLSTM_CRF(len_, to_ix_l, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "model.load_state_dict(torch.load(os.path.join(os.getcwd(),\"model\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据，分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming..... 57037793_in.txt\n",
      "transforming..... 57037794_in.txt\n",
      "transforming..... 57037795_in.txt\n",
      "transforming..... 57037796_in.txt\n",
      "transforming..... 57037797_in.txt\n",
      "transforming..... 57037798_in.txt\n",
      "transforming..... 57037799_in.txt\n",
      "transforming..... 57037800_in.txt\n",
      "transforming..... 57037801_in.txt\n",
      "transforming..... 57037802_in.txt\n",
      "transforming..... 57037803_in.txt\n",
      "transforming..... 57037804_in.txt\n",
      "transforming..... 57037805_in.txt\n",
      "transforming..... 57037806_in.txt\n",
      "transforming..... 57037807_in.txt\n",
      "transforming..... 57037808_in.txt\n",
      "transforming..... 57037809_in.txt\n",
      "transforming..... 57037810_in.txt\n",
      "transforming..... 57037811_in.txt\n",
      "transforming..... 57037812_in.txt\n",
      "transforming..... 57037813_in.txt\n",
      "transforming..... 57037814_in.txt\n",
      "transforming..... 57037815_in.txt\n",
      "transforming..... 57037816_in.txt\n",
      "transforming..... 57037817_in.txt\n",
      "transforming..... 57037818_in.txt\n",
      "transforming..... 57037819_in.txt\n",
      "transforming..... 57037820_in.txt\n",
      "transforming..... 57037821_in.txt\n",
      "transforming..... 57037822_in.txt\n",
      "transforming..... 57037823_in.txt\n",
      "transforming..... 57037824_in.txt\n",
      "transforming..... 57037825_in.txt\n",
      "transforming..... 57037826_in.txt\n",
      "transforming..... 57037827_in.txt\n",
      "transforming..... 57037828_in.txt\n",
      "transforming..... 57037829_in.txt\n",
      "transforming..... 57037830_in.txt\n",
      "transforming..... 57037831_in.txt\n",
      "transforming..... 57037832_in.txt\n",
      "transforming..... 57037833_in.txt\n",
      "transforming..... 57037834_in.txt\n",
      "transforming..... 57037835_in.txt\n",
      "transforming..... 57037836_in.txt\n",
      "transforming..... 57037837_in.txt\n",
      "transforming..... 57037838_in.txt\n",
      "transforming..... 57037839_in.txt\n",
      "transforming..... 57037840_in.txt\n",
      "transforming..... 57037841_in.txt\n",
      "transforming..... 57037842_in.txt\n",
      "transforming..... 57037843_in.txt\n",
      "transforming..... 57037844_in.txt\n",
      "transforming..... 57037845_in.txt\n",
      "transforming..... 57037846_in.txt\n",
      "transforming..... 57037847_in.txt\n",
      "transforming..... 57037848_in.txt\n",
      "transforming..... 57037849_in.txt\n",
      "transforming..... 57037850_in.txt\n",
      "transforming..... 57037851_in.txt\n",
      "transforming..... 57037852_in.txt\n",
      "transforming..... 57037853_in.txt\n",
      "transforming..... 57037854_in.txt\n",
      "transforming..... 57037855_in.txt\n",
      "transforming..... 57037856_in.txt\n",
      "transforming..... 57037857_in.txt\n",
      "transforming..... 57037858_in.txt\n",
      "transforming..... 57037859_in.txt\n",
      "transforming..... 57037860_in.txt\n",
      "transforming..... 57037861_in.txt\n",
      "transforming..... 57037862_in.txt\n",
      "transforming..... 57037863_in.txt\n",
      "transforming..... 57037864_in.txt\n",
      "transforming..... 57037865_in.txt\n",
      "transforming..... 57037866_in.txt\n",
      "transforming..... 57037867_in.txt\n",
      "transforming..... 57037868_in.txt\n",
      "transforming..... 57037869_in.txt\n",
      "transforming..... 57037870_in.txt\n",
      "transforming..... 57037871_in.txt\n",
      "transforming..... 57037872_in.txt\n",
      "transforming..... 57037873_in.txt\n",
      "transforming..... 57037874_in.txt\n",
      "transforming..... 57037875_in.txt\n",
      "transforming..... 57037876_in.txt\n",
      "transforming..... 57037877_in.txt\n",
      "transforming..... 57037878_in.txt\n",
      "transforming..... 57037879_in.txt\n"
     ]
    }
   ],
   "source": [
    "def stopwordslist(filepath=r\"D:\\DEV\\businessInfomationProject\\NER\\stopwords.txt\"):  \n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]  \n",
    "    return stopwords\n",
    "\n",
    "\n",
    "stopwords = stopwordslist()\n",
    "import codecs\n",
    "PATH = r\"D:\\DEV\\businessInfomationProject\\TextRank4ZH_v2\\news\\newsin\"\n",
    "for parent, dirnames, filenames in os.walk(PATH):\n",
    "    for filename in filenames:\n",
    "        print(\"transforming.....\", filename)\n",
    "        file_path_in = os.path.join(parent, filename)\n",
    "        file_path_out = os.path.join(parent ,r\"..\\\\NERout\\\\ner_{}\".format(filename))\n",
    "        test_d = codecs.open(file_path_in, 'r', 'utf-8').read()\n",
    "        test_d = re.sub(r\"\\n\\n\",\"\",test_d)\n",
    "        test_d = re.sub(r\"\\d+\",\"MM\",test_d)\n",
    "        for i in ([\"一\",\"二\",\"三\",\"四\",\"五\",\"六\",\"七\",\"八\",\"九\",\"十\"]):\n",
    "            test_d = re.sub(i,\"MM\",test_d) \n",
    "        test_d_Lst = cut_sentence(test_d)\n",
    "        \n",
    "        result = set()\n",
    "        for sent in test_d_Lst:\n",
    "            if len(sent) == 0 :continue\n",
    "            test_d_ = filterdata(sent,[])\n",
    "            test_w,_ = dosegment_all(test_d_,user_dict)\n",
    "                    \n",
    "             \n",
    "            test_id = [to_ix_w[i] if i in to_ix_w.keys() else 3 for i in test_w]\n",
    "            if len(set(test_id))<=2:continue\n",
    "            test_res_ = torch.tensor(test_id,dtype=torch.long)\n",
    "            predict_res = model(test_res_)[1]\n",
    "            \n",
    "\n",
    "            for ix,k in enumerate(predict_res):\n",
    "                if to_l_ix[k] in [\"org_name\",\"company_name\",\"person_name\"]:\n",
    "                    if test_w[ix] not in stopwords:\n",
    "                        result.add(test_w[ix]+\" \"+to_l_ix[k])\n",
    "        with codecs.open(file_path_out, 'w+', 'utf-8') as surveyp:\n",
    "            surveyp.write(\",\\n\".join(result))\n",
    "            \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MM天',\n",
       " '《',\n",
       " '东方',\n",
       " '为',\n",
       " '为期',\n",
       " '之',\n",
       " '交响音乐会',\n",
       " '从',\n",
       " '以及',\n",
       " '众多',\n",
       " '到',\n",
       " '即墨',\n",
       " '国乐',\n",
       " '国际',\n",
       " '在',\n",
       " '多部',\n",
       " '大型',\n",
       " '大师',\n",
       " '师生',\n",
       " '带来',\n",
       " '期间',\n",
       " '汇聚',\n",
       " '海内外',\n",
       " '海洋',\n",
       " '的',\n",
       " '知名',\n",
       " '等',\n",
       " '红旗',\n",
       " '西方',\n",
       " '观众',\n",
       " '阎师',\n",
       " '阎维文',\n",
       " '青岛',\n",
       " '音',\n",
       " '音乐会',\n",
       " '音乐季',\n",
       " '音乐家',\n",
       " '颂',\n",
       " '高山流水',\n",
       " '高徒'}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(training_batch))\n",
    "for i,v in training_batch:\n",
    "    print(len(i) == len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 500])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
